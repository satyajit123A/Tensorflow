{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sonar.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satyajit123A/Tensorflow/blob/master/Sonar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "AHFxyFgv486q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Sonar Classifier**\n",
        "\n",
        "![sonar](https://www.km.kongsberg.com/ks/web/nokbg0239.nsf/obj/Naval-sonar-ASW-and-mine-hunting-1020x514.jpg/$File/Naval-sonar-ASW-and-mine-hunting-1020x514.jpg)\n",
        "\n",
        "\n",
        "# **Data Set Information:**\n",
        "\n",
        "The file \"sonar.mines\" contains 111 patterns obtained by bouncing sonar signals off a metal cylinder at various angles and under various conditions. The file \"sonar.rocks\" contains 97 patterns obtained from rocks under similar conditions. The transmitted sonar signal is a frequency-modulated chirp, rising in frequency. The data set contains signals obtained from a variety of different aspect angles, spanning 90 degrees for the cylinder and 180 degrees for the rock.\n",
        "\n",
        "Each pattern is a set of 60 numbers in the range 0.0 to 1.0. Each number represents the energy within a particular frequency band, integrated over a certain period of time. The integration aperture for higher frequencies occur later in time, since these frequencies are transmitted later during the chirp.\n",
        "\n",
        "The label associated with each record contains the letter \"R\" if the object is a rock and \"M\" if it is a mine (metal cylinder). The numbers in the labels are in increasing order of aspect angle, but they do not encode the angle directly.\n",
        "\n",
        "\n",
        "# Download the data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "3-W35v006UrN",
        "colab_type": "code",
        "outputId": "a0ebdd9d-678e-4000-c93d-b5ae0d66c7b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-16 01:22:13--  https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.249\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.249|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87776 (86K) [text/plain]\n",
            "Saving to: ‘sonar.all-data’\n",
            "\n",
            "sonar.all-data      100%[===================>]  85.72K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-03-16 01:22:18 (710 KB/s) - ‘sonar.all-data’ saved [87776/87776]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RXGjW2166toq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Rename the DataFile\n",
        "\n",
        "Rename the datafile to sonar.csv"
      ]
    },
    {
      "metadata": {
        "id": "kwNOLlhP6dN9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mv sonar.all-data sonar.csv\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "neseCIZs7BMX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Convert Text Labels to Integers"
      ]
    },
    {
      "metadata": {
        "id": "NE4stA0v68_C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "!sed -i -e 's/M/0/g' sonar.csv\n",
        "!sed -i -e 's/R/1/g' sonar.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BzYLg_TH7QeF",
        "colab_type": "code",
        "outputId": "5ff65427-11ec-4d16-e0f2-ba5df9b8cb91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "!head sonar.csv"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0200,0.0371,0.0428,0.0207,0.0954,0.0986,0.1539,0.1601,0.3109,0.2111,0.1609,0.1582,0.2238,0.0645,0.0660,0.2273,0.3100,0.2999,0.5078,0.4797,0.5783,0.5071,0.4328,0.5550,0.6711,0.6415,0.7104,0.8080,0.6791,0.3857,0.1307,0.2604,0.5121,0.7547,0.8537,0.8507,0.6692,0.6097,0.4943,0.2744,0.0510,0.2834,0.2825,0.4256,0.2641,0.1386,0.1051,0.1343,0.0383,0.0324,0.0232,0.0027,0.0065,0.0159,0.0072,0.0167,0.0180,0.0084,0.0090,0.0032,1\n",
            "0.0453,0.0523,0.0843,0.0689,0.1183,0.2583,0.2156,0.3481,0.3337,0.2872,0.4918,0.6552,0.6919,0.7797,0.7464,0.9444,1.0000,0.8874,0.8024,0.7818,0.5212,0.4052,0.3957,0.3914,0.3250,0.3200,0.3271,0.2767,0.4423,0.2028,0.3788,0.2947,0.1984,0.2341,0.1306,0.4182,0.3835,0.1057,0.1840,0.1970,0.1674,0.0583,0.1401,0.1628,0.0621,0.0203,0.0530,0.0742,0.0409,0.0061,0.0125,0.0084,0.0089,0.0048,0.0094,0.0191,0.0140,0.0049,0.0052,0.0044,1\n",
            "0.0262,0.0582,0.1099,0.1083,0.0974,0.2280,0.2431,0.3771,0.5598,0.6194,0.6333,0.7060,0.5544,0.5320,0.6479,0.6931,0.6759,0.7551,0.8929,0.8619,0.7974,0.6737,0.4293,0.3648,0.5331,0.2413,0.5070,0.8533,0.6036,0.8514,0.8512,0.5045,0.1862,0.2709,0.4232,0.3043,0.6116,0.6756,0.5375,0.4719,0.4647,0.2587,0.2129,0.2222,0.2111,0.0176,0.1348,0.0744,0.0130,0.0106,0.0033,0.0232,0.0166,0.0095,0.0180,0.0244,0.0316,0.0164,0.0095,0.0078,1\n",
            "0.0100,0.0171,0.0623,0.0205,0.0205,0.0368,0.1098,0.1276,0.0598,0.1264,0.0881,0.1992,0.0184,0.2261,0.1729,0.2131,0.0693,0.2281,0.4060,0.3973,0.2741,0.3690,0.5556,0.4846,0.3140,0.5334,0.5256,0.2520,0.2090,0.3559,0.6260,0.7340,0.6120,0.3497,0.3953,0.3012,0.5408,0.8814,0.9857,0.9167,0.6121,0.5006,0.3210,0.3202,0.4295,0.3654,0.2655,0.1576,0.0681,0.0294,0.0241,0.0121,0.0036,0.0150,0.0085,0.0073,0.0050,0.0044,0.0040,0.0117,1\n",
            "0.0762,0.0666,0.0481,0.0394,0.0590,0.0649,0.1209,0.2467,0.3564,0.4459,0.4152,0.3952,0.4256,0.4135,0.4528,0.5326,0.7306,0.6193,0.2032,0.4636,0.4148,0.4292,0.5730,0.5399,0.3161,0.2285,0.6995,1.0000,0.7262,0.4724,0.5103,0.5459,0.2881,0.0981,0.1951,0.4181,0.4604,0.3217,0.2828,0.2430,0.1979,0.2444,0.1847,0.0841,0.0692,0.0528,0.0357,0.0085,0.0230,0.0046,0.0156,0.0031,0.0054,0.0105,0.0110,0.0015,0.0072,0.0048,0.0107,0.0094,1\n",
            "0.0286,0.0453,0.0277,0.0174,0.0384,0.0990,0.1201,0.1833,0.2105,0.3039,0.2988,0.4250,0.6343,0.8198,1.0000,0.9988,0.9508,0.9025,0.7234,0.5122,0.2074,0.3985,0.5890,0.2872,0.2043,0.5782,0.5389,0.3750,0.3411,0.5067,0.5580,0.4778,0.3299,0.2198,0.1407,0.2856,0.3807,0.4158,0.4054,0.3296,0.2707,0.2650,0.0723,0.1238,0.1192,0.1089,0.0623,0.0494,0.0264,0.0081,0.0104,0.0045,0.0014,0.0038,0.0013,0.0089,0.0057,0.0027,0.0051,0.0062,1\n",
            "0.0317,0.0956,0.1321,0.1408,0.1674,0.1710,0.0731,0.1401,0.2083,0.3513,0.1786,0.0658,0.0513,0.3752,0.5419,0.5440,0.5150,0.4262,0.2024,0.4233,0.7723,0.9735,0.9390,0.5559,0.5268,0.6826,0.5713,0.5429,0.2177,0.2149,0.5811,0.6323,0.2965,0.1873,0.2969,0.5163,0.6153,0.4283,0.5479,0.6133,0.5017,0.2377,0.1957,0.1749,0.1304,0.0597,0.1124,0.1047,0.0507,0.0159,0.0195,0.0201,0.0248,0.0131,0.0070,0.0138,0.0092,0.0143,0.0036,0.0103,1\n",
            "0.0519,0.0548,0.0842,0.0319,0.1158,0.0922,0.1027,0.0613,0.1465,0.2838,0.2802,0.3086,0.2657,0.3801,0.5626,0.4376,0.2617,0.1199,0.6676,0.9402,0.7832,0.5352,0.6809,0.9174,0.7613,0.8220,0.8872,0.6091,0.2967,0.1103,0.1318,0.0624,0.0990,0.4006,0.3666,0.1050,0.1915,0.3930,0.4288,0.2546,0.1151,0.2196,0.1879,0.1437,0.2146,0.2360,0.1125,0.0254,0.0285,0.0178,0.0052,0.0081,0.0120,0.0045,0.0121,0.0097,0.0085,0.0047,0.0048,0.0053,1\n",
            "0.0223,0.0375,0.0484,0.0475,0.0647,0.0591,0.0753,0.0098,0.0684,0.1487,0.1156,0.1654,0.3833,0.3598,0.1713,0.1136,0.0349,0.3796,0.7401,0.9925,0.9802,0.8890,0.6712,0.4286,0.3374,0.7366,0.9611,0.7353,0.4856,0.1594,0.3007,0.4096,0.3170,0.3305,0.3408,0.2186,0.2463,0.2726,0.1680,0.2792,0.2558,0.1740,0.2121,0.1099,0.0985,0.1271,0.1459,0.1164,0.0777,0.0439,0.0061,0.0145,0.0128,0.0145,0.0058,0.0049,0.0065,0.0093,0.0059,0.0022,1\n",
            "0.0164,0.0173,0.0347,0.0070,0.0187,0.0671,0.1056,0.0697,0.0962,0.0251,0.0801,0.1056,0.1266,0.0890,0.0198,0.1133,0.2826,0.3234,0.3238,0.4333,0.6068,0.7652,0.9203,0.9719,0.9207,0.7545,0.8289,0.8907,0.7309,0.6896,0.5829,0.4935,0.3101,0.0306,0.0244,0.1108,0.1594,0.1371,0.0696,0.0452,0.0620,0.1421,0.1597,0.1384,0.0372,0.0688,0.0867,0.0513,0.0092,0.0198,0.0118,0.0090,0.0223,0.0179,0.0084,0.0068,0.0032,0.0035,0.0056,0.0040,1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LEjAqt5P7bip",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Build a Neural Network\n",
        "Build a Keras Neural Network to Process the data file. By training a Neural Network we are feeding the network the features and asking it to make a prediction of which class of object those readings are from.\n",
        "\n",
        "We will build a Feed Forward Neural Network using Keras Sequential Model.\n",
        "\n",
        "First some imports"
      ]
    },
    {
      "metadata": {
        "id": "RGwEYiew7Us7",
        "colab_type": "code",
        "outputId": "f407b946-2516-4764-dc64-4a2dd4531181",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "9nPDzDNT7wb2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Working With Datasets\n",
        "\n",
        "# Set Random Seed\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "2B2w3lvo8B8_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "isGNvLkU8Izw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load the data into a pandas dataframe and Split into Features and Labels"
      ]
    },
    {
      "metadata": {
        "id": "LolvXwJe8S2V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "dataframe = pandas.read_csv(\"sonar.csv\", header=None)\n",
        "dataset = dataframe.values\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:60].astype(float)\n",
        "Y = dataset[:,60]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0sXp1ikK8yz5",
        "colab_type": "code",
        "outputId": "6e36b7c8-488f-4d2c-f81e-a7e737fa710c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3553
        }
      },
      "cell_type": "code",
      "source": [
        "# encode class values as integers\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "encoded_Y = encoder.transform(Y)\n",
        "\n",
        "# convert integers to dummy variables (hot encoded)\n",
        "dummy_y = np_utils.to_categorical(encoded_Y)\n",
        "print(dummy_y)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cVOtrp1Z89H6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Build a model"
      ]
    },
    {
      "metadata": {
        "id": "qSaX1umT9H-U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "723c3bc2-6efa-4aad-e39a-0b36170db879"
      },
      "cell_type": "code",
      "source": [
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(60, input_dim=60, activation='relu'))\n",
        "model.add(Dense(40, activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1gyWCUak-EyW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Compile the Model and Train\n"
      ]
    },
    {
      "metadata": {
        "id": "q0IpDfY5-XOh",
        "colab_type": "code",
        "outputId": "091ceafa-0be7-49fb-95cd-f1e227c6c3e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2145
        }
      },
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, dummy_y, epochs=60, batch_size=128)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/60\n",
            "208/208 [==============================] - 1s 4ms/step - loss: 0.6825 - acc: 0.5337\n",
            "Epoch 2/60\n",
            "208/208 [==============================] - 0s 50us/step - loss: 0.6739 - acc: 0.5577\n",
            "Epoch 3/60\n",
            "208/208 [==============================] - 0s 38us/step - loss: 0.6662 - acc: 0.5577\n",
            "Epoch 4/60\n",
            "208/208 [==============================] - 0s 35us/step - loss: 0.6563 - acc: 0.5769\n",
            "Epoch 5/60\n",
            "208/208 [==============================] - 0s 30us/step - loss: 0.6487 - acc: 0.5865\n",
            "Epoch 6/60\n",
            "208/208 [==============================] - 0s 25us/step - loss: 0.6417 - acc: 0.6058\n",
            "Epoch 7/60\n",
            "208/208 [==============================] - 0s 45us/step - loss: 0.6338 - acc: 0.6394\n",
            "Epoch 8/60\n",
            "208/208 [==============================] - 0s 39us/step - loss: 0.6254 - acc: 0.6779\n",
            "Epoch 9/60\n",
            "208/208 [==============================] - 0s 51us/step - loss: 0.6188 - acc: 0.6923\n",
            "Epoch 10/60\n",
            "208/208 [==============================] - 0s 46us/step - loss: 0.6113 - acc: 0.6875\n",
            "Epoch 11/60\n",
            "208/208 [==============================] - 0s 33us/step - loss: 0.6037 - acc: 0.6923\n",
            "Epoch 12/60\n",
            "208/208 [==============================] - 0s 30us/step - loss: 0.5964 - acc: 0.7019\n",
            "Epoch 13/60\n",
            "208/208 [==============================] - 0s 27us/step - loss: 0.5876 - acc: 0.7115\n",
            "Epoch 14/60\n",
            "208/208 [==============================] - 0s 27us/step - loss: 0.5791 - acc: 0.7356\n",
            "Epoch 15/60\n",
            "208/208 [==============================] - 0s 31us/step - loss: 0.5714 - acc: 0.7404\n",
            "Epoch 16/60\n",
            "208/208 [==============================] - 0s 29us/step - loss: 0.5614 - acc: 0.7404\n",
            "Epoch 17/60\n",
            "208/208 [==============================] - 0s 31us/step - loss: 0.5524 - acc: 0.7308\n",
            "Epoch 18/60\n",
            "208/208 [==============================] - 0s 31us/step - loss: 0.5426 - acc: 0.7452\n",
            "Epoch 19/60\n",
            "208/208 [==============================] - 0s 27us/step - loss: 0.5329 - acc: 0.7548\n",
            "Epoch 20/60\n",
            "208/208 [==============================] - 0s 34us/step - loss: 0.5223 - acc: 0.7740\n",
            "Epoch 21/60\n",
            "208/208 [==============================] - 0s 30us/step - loss: 0.5122 - acc: 0.7788\n",
            "Epoch 22/60\n",
            "208/208 [==============================] - 0s 30us/step - loss: 0.5016 - acc: 0.7740\n",
            "Epoch 23/60\n",
            "208/208 [==============================] - 0s 25us/step - loss: 0.4920 - acc: 0.7740\n",
            "Epoch 24/60\n",
            "208/208 [==============================] - 0s 41us/step - loss: 0.4814 - acc: 0.8029\n",
            "Epoch 25/60\n",
            "208/208 [==============================] - 0s 36us/step - loss: 0.4719 - acc: 0.8221\n",
            "Epoch 26/60\n",
            "208/208 [==============================] - 0s 47us/step - loss: 0.4634 - acc: 0.8317\n",
            "Epoch 27/60\n",
            "208/208 [==============================] - 0s 37us/step - loss: 0.4544 - acc: 0.8077\n",
            "Epoch 28/60\n",
            "208/208 [==============================] - 0s 29us/step - loss: 0.4458 - acc: 0.8029\n",
            "Epoch 29/60\n",
            "208/208 [==============================] - 0s 37us/step - loss: 0.4350 - acc: 0.8365\n",
            "Epoch 30/60\n",
            "208/208 [==============================] - 0s 42us/step - loss: 0.4275 - acc: 0.8606\n",
            "Epoch 31/60\n",
            "208/208 [==============================] - 0s 44us/step - loss: 0.4192 - acc: 0.8462\n",
            "Epoch 32/60\n",
            "208/208 [==============================] - 0s 29us/step - loss: 0.4114 - acc: 0.8413\n",
            "Epoch 33/60\n",
            "208/208 [==============================] - 0s 42us/step - loss: 0.4034 - acc: 0.8510\n",
            "Epoch 34/60\n",
            "208/208 [==============================] - 0s 39us/step - loss: 0.3966 - acc: 0.8558\n",
            "Epoch 35/60\n",
            "208/208 [==============================] - 0s 33us/step - loss: 0.3895 - acc: 0.8606\n",
            "Epoch 36/60\n",
            "208/208 [==============================] - 0s 33us/step - loss: 0.3841 - acc: 0.8702\n",
            "Epoch 37/60\n",
            "208/208 [==============================] - 0s 33us/step - loss: 0.3767 - acc: 0.8558\n",
            "Epoch 38/60\n",
            "208/208 [==============================] - 0s 31us/step - loss: 0.3710 - acc: 0.8510\n",
            "Epoch 39/60\n",
            "208/208 [==============================] - 0s 29us/step - loss: 0.3653 - acc: 0.8702\n",
            "Epoch 40/60\n",
            "208/208 [==============================] - 0s 28us/step - loss: 0.3598 - acc: 0.8702\n",
            "Epoch 41/60\n",
            "208/208 [==============================] - 0s 31us/step - loss: 0.3566 - acc: 0.8654\n",
            "Epoch 42/60\n",
            "208/208 [==============================] - 0s 32us/step - loss: 0.3536 - acc: 0.8702\n",
            "Epoch 43/60\n",
            "208/208 [==============================] - 0s 31us/step - loss: 0.3438 - acc: 0.8798\n",
            "Epoch 44/60\n",
            "208/208 [==============================] - 0s 30us/step - loss: 0.3389 - acc: 0.8750\n",
            "Epoch 45/60\n",
            "208/208 [==============================] - 0s 35us/step - loss: 0.3358 - acc: 0.8750\n",
            "Epoch 46/60\n",
            "208/208 [==============================] - 0s 34us/step - loss: 0.3290 - acc: 0.8846\n",
            "Epoch 47/60\n",
            "208/208 [==============================] - 0s 34us/step - loss: 0.3279 - acc: 0.8846\n",
            "Epoch 48/60\n",
            "208/208 [==============================] - 0s 34us/step - loss: 0.3224 - acc: 0.8894\n",
            "Epoch 49/60\n",
            "208/208 [==============================] - 0s 34us/step - loss: 0.3191 - acc: 0.8798\n",
            "Epoch 50/60\n",
            "208/208 [==============================] - 0s 34us/step - loss: 0.3124 - acc: 0.8990\n",
            "Epoch 51/60\n",
            "208/208 [==============================] - 0s 34us/step - loss: 0.3119 - acc: 0.8942\n",
            "Epoch 52/60\n",
            "208/208 [==============================] - 0s 37us/step - loss: 0.3052 - acc: 0.9087\n",
            "Epoch 53/60\n",
            "208/208 [==============================] - 0s 32us/step - loss: 0.3023 - acc: 0.8942\n",
            "Epoch 54/60\n",
            "208/208 [==============================] - 0s 33us/step - loss: 0.2967 - acc: 0.9087\n",
            "Epoch 55/60\n",
            "208/208 [==============================] - 0s 31us/step - loss: 0.2941 - acc: 0.8942\n",
            "Epoch 56/60\n",
            "208/208 [==============================] - 0s 30us/step - loss: 0.2896 - acc: 0.9038\n",
            "Epoch 57/60\n",
            "208/208 [==============================] - 0s 28us/step - loss: 0.2890 - acc: 0.8942\n",
            "Epoch 58/60\n",
            "208/208 [==============================] - 0s 30us/step - loss: 0.2827 - acc: 0.9038\n",
            "Epoch 59/60\n",
            "208/208 [==============================] - 0s 50us/step - loss: 0.2809 - acc: 0.9087\n",
            "Epoch 60/60\n",
            "208/208 [==============================] - 0s 49us/step - loss: 0.2773 - acc: 0.9038\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8193c9be10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "XQQCJ4f4-_S7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Save The Model\n",
        "The Model will be loaded into dl4j and run in a Spark context. A saved model includes the weights and the computation graph needed for either further training or inference. In this example we will load the model into dl4j and pass it our datafile and evaluate the accuracy of the model in dl4j running in spark."
      ]
    },
    {
      "metadata": {
        "id": "TTYPRhCN_Vxo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('my_modelx.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-IqhrHjW_bwX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Verify  model has saved"
      ]
    },
    {
      "metadata": {
        "id": "qpckB42I_emu",
        "colab_type": "code",
        "outputId": "01574d0b-c579-4580-f530-284f4364f0b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_modelx.h5  sample_data  sonar.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DlJiWDTSE28E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Create A Custom Model According to your Mood(mine:only 90%)"
      ]
    },
    {
      "metadata": {
        "id": "7B-p9vImFGtT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.90):\n",
        "      print(\"\\nReached 90% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z_bVqHVYFpN8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "6be51494-9946-4330-d055-103a69055ba4"
      },
      "cell_type": "code",
      "source": [
        "callbacks = myCallback()\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, dummy_y, epochs=60, batch_size=128,callbacks=[callbacks])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "208/208 [==============================] - 0s 1ms/step - loss: 0.2776 - acc: 0.8846\n",
            "Epoch 2/60\n",
            "208/208 [==============================] - 0s 35us/step - loss: 0.2837 - acc: 0.9038\n",
            "\n",
            "Reached 90% accuracy so cancelling training!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8193b62f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "QCIj_jTyGbeJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "don't execute the first model to actually train  this one \n",
        "I believe in first attempt never give your best save it for Appraisal \n",
        "![promosion](http://www.assignmentpoint.com/wp-content/uploads/2017/09/Employees-Promotion.jpg)"
      ]
    },
    {
      "metadata": {
        "id": "eW-UnI4r_rHp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Run your code in DL4J on Spark\n",
        "DL4J has a KerasModelImport feature. Java code has been written and compiled that will import a keras model, run the model on a spark cluster.\n",
        "\n",
        "You can view the code here.\n",
        "\n",
        "https://github.com/maxpumperla/dl4j_coursera/blob/master/src/main/java/skymind/dsx/KerasImportCSVSparkRunner.java"
      ]
    },
    {
      "metadata": {
        "id": "TBIpTOJl_zPd",
        "colab_type": "code",
        "outputId": "3229273c-34d8-4d10-c6b4-8f132edee16e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://github.com/maxpumperla/dl4j_coursera/releases/download/v0.4/dl4j-snapshot.jar"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-16 00:56:05--  https://github.com/maxpumperla/dl4j_coursera/releases/download/v0.4/dl4j-snapshot.jar\n",
            "Resolving github.com (github.com)... 192.30.253.112, 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/113966420/3472050e-f84b-11e7-90f0-d69fe0bedce0?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190316%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190316T005606Z&X-Amz-Expires=300&X-Amz-Signature=1a4ee19eb911265aeb11b48205fc9d1c7a80ade05ee9a13dbed967c74c9dcfb3&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Ddl4j-snapshot.jar&response-content-type=application%2Foctet-stream [following]\n",
            "--2019-03-16 00:56:06--  https://github-production-release-asset-2e65be.s3.amazonaws.com/113966420/3472050e-f84b-11e7-90f0-d69fe0bedce0?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190316%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190316T005606Z&X-Amz-Expires=300&X-Amz-Signature=1a4ee19eb911265aeb11b48205fc9d1c7a80ade05ee9a13dbed967c74c9dcfb3&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Ddl4j-snapshot.jar&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.161.131\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.161.131|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 486534267 (464M) [application/octet-stream]\n",
            "Saving to: ‘dl4j-snapshot.jar’\n",
            "\n",
            "dl4j-snapshot.jar   100%[===================>] 464.00M  45.7MB/s    in 11s     \n",
            "\n",
            "2019-03-16 00:56:17 (43.8 MB/s) - ‘dl4j-snapshot.jar’ saved [486534267/486534267]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BsHB33i1AA-e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Run code in Spark\n",
        "The output from Spark is rather verbose, lots of notices and warnings.\n",
        "\n",
        "This code will take time.\n",
        "\n",
        "To verify success look for output similar to this at the end.\n",
        "\n",
        "==========================Scores========================================\n",
        "  of classes:    2\n",
        "  \n",
        " Accuracy:        0.7933\n",
        " \n",
        " Precision:       0.8064\n",
        " \n",
        " Recall:          0.7855\n",
        " \n",
        " F1 Score:        0.7514\n",
        " \n",
        "========================================================================"
      ]
    },
    {
      "metadata": {
        "id": "QMet5UFyAsnK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# DONE \n",
        "\n",
        "![Thank you](https://previews.123rf.com/images/blamb/blamb1405/blamb140500165/28030318-colourful-cartoon-text-reading-thank-you-.jpg)"
      ]
    }
  ]
}